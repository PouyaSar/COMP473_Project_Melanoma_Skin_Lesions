Working version


import cv2
import numpy as np
from skimage.segmentation import chan_vese
from skimage import exposure
from skimage.measure import label, regionprops
from skimage.morphology import remove_small_objects
from skimage.filters import median
from skimage.color import rgb2gray
from skimage import img_as_float

def remove_hairs(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 9))

    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)
    _, thresh = cv2.threshold(blackhat, 10, 255, cv2.THRESH_BINARY)

    result = cv2.inpaint(img, thresh, 3, cv2.INPAINT_TELEA)
    return result

def contour(cleaned_img):

    gray = cv2.cvtColor(cleaned_img, cv2.COLOR_BGR2GRAY)
    #gray_blur = cv2.GaussianBlur(gray, (7, 7), 0)
    #gray_eq = exposure.equalize_adapthist(gray, clip_limit=0.03)
    img_float = gray.astype(np.float32)

    h, w = img_float.shape
    Y, X = np.ogrid[:h, :w]
    center_x, center_y = w // 2, h // 2
    radius = min(h, w) // 4
    init_ls = (X - center_x)**2 + (Y - center_y)**2 < radius**2

    # Apply Chan-Vese
    img_countour = chan_vese(img_float, mu=0.1, lambda1=1, lambda2=1, 
                            tol=1e-4, max_num_iter=300, init_level_set=init_ls, extended_output=False)
    
    mask = img_countour.astype(np.uint8) * 255
    
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if len(contours) == 0:
        return mask

    largest = max(contours, key=cv2.contourArea)
    final_mask = np.zeros_like(mask)
    cv2.drawContours(final_mask, [largest], -1, 255, -1)

    return final_mask

def compute_asymmetry(largest_contour):
    
    M = cv2.moments(largest_contour)
    cx = int(M['m10'] / M['m00'])
    cy = int(M['m01'] / M['m00'])
    
    props = regionprops(largest_contour.astype(np.uint8))[0]
    orientation = props.orientation
    
    M = cv2.getRotationMatrix2D((cx, cy), -np.degrees(orientation), 1.0)
    rotated = cv2.warpAffine(largest_contour.astype(np.uint8), M, (largest_contour.shape[1], largest_contour.shape[0]))
    
    flipped_x = cv2.flip(rotated, 1)  # horizontal
    
    delta_x = np.logical_xor(rotated, flipped_x).sum()
    AS1 = delta_x / rotated.sum()

    flipped_y = cv2.flip(rotated, 0)  # vertical
    delta_y = np.logical_xor(rotated, flipped_y).sum()
    AS2 = delta_y / rotated.sum()

    return AS1, AS2  
    



if __name__ == "__main__":
    img = cv2.imread('HAM10000\ISIC_0035995.jpg')
    if img is not None:
        final_img = remove_hairs(img)
        mask = contour(final_img).astype(np.uint8) * 255
        
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)
        largest_contour = sorted_contours[0]
        
        image_countours = final_img.copy()
        cv2.drawContours(image_countours, contours, -1, (0, 255, 0), 2)
        
        # Create a mask for the largest contour
        final_mask = np.zeros_like(mask)
        
        cv2.drawContours(final_mask, [largest_contour], 0, (255), thickness=cv2.FILLED)
        AS1, AS2 = compute_asymmetry(largest_contour)
        print(f"Asymmetry Scores: AS1 = {AS1}, AS2 = {AS2}")
        
        cv2.imshow("Original", img)
        cv2.imshow("Result", final_img)
        cv2.imshow("Contour Mask", image_countours)
        cv2.imshow("Largest Contour Mask", final_mask)
        cv2.waitKey(0)
        cv2.destroyAllWindows()